{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "ROOT = Path(\"../\")\n",
    "DATA = ROOT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "import cv2\n",
    "from dvclive import Live\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and split it into train/test\n",
    "\n",
    "We have some [data in DVC](https://dvc.org/doc/start/data-management/data-versioning) that we can pull. \n",
    "\n",
    "This data includes:\n",
    "* satellite images\n",
    "* masks of the swimming pools in each satellite image\n",
    "\n",
    "DVC can help connect your data to your repo, but it isn't necessary to have your data in DVC to start tracking experiments with DVC and DVCLive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to YOLO Dataset format\n",
    "\n",
    "https://docs.ultralytics.com/datasets/segment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_yolo_annotation(mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    annotation = \"\"\n",
    "    for contour in contours:\n",
    "        single_annotation = \"0\"\n",
    "        for row, col in contour.squeeze():\n",
    "            single_annotation += f\" {round(col / mask.shape[1], 3)} {round(row / mask.shape[0], 3)}\"\n",
    "        annotation += f\"{single_annotation}\\n\"\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_regions = [\"REGION_1-\"]\n",
    "\n",
    "train_data_dir = DATA / \"yolo_dataset\" / \"train\"\n",
    "train_data_dir.mkdir(exist_ok=True, parents=True)\n",
    "test_data_dir = DATA / \"yolo_dataset\" / \"val\"\n",
    "test_data_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for img_path in DATA.glob(\"pool_data/images/*.jpg\"):\n",
    "    yolo_annotation = mask_to_yolo_annotation(\n",
    "        cv2.imread(\n",
    "            str(DATA / \"pool_data\" / \"masks\" / f\"{img_path.stem}.png\"),\n",
    "            cv2.IMREAD_GRAYSCALE\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if any(region in str(img_path) for region in test_regions):\n",
    "        dst = test_data_dir / img_path.name\n",
    "    else:\n",
    "        dst = train_data_dir / img_path.name\n",
    "\n",
    "    shutil.copy(img_path, dst)\n",
    "    dst.with_suffix(\".txt\").write_text(yolo_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_dataset_yaml = DATA / \"yolo_dataset.yaml\"\n",
    "yolo_dataset_yaml.write_text(\n",
    "    \"\"\"\n",
    "path: ./yolo_dataset\n",
    "train: train\n",
    "val: val\n",
    "\n",
    "names:\n",
    "  0: swimming_pool\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train multiple models with different number of epochs\n",
    "Set up model training, using DVCLive to capture the results of each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_callbacks(live, yolo):\n",
    "    def _log_confusion_matrix(validator, live):\n",
    "        targets = []\n",
    "        preds = []\n",
    "        matrix = validator.confusion_matrix.matrix\n",
    "        names = list(validator.names.values())\n",
    "        if validator.confusion_matrix.task == \"detect\":\n",
    "            names += [\"background\"]\n",
    "\n",
    "        for ti, pred in enumerate(matrix.T.astype(int)):\n",
    "            for pi, num in enumerate(pred):\n",
    "                targets.extend([names[ti]] * num)\n",
    "                preds.extend([names[pi]] * num)\n",
    "\n",
    "        live.log_sklearn_plot(\"confusion_matrix\", targets, preds)\n",
    "\n",
    "    def on_train_epoch_start(trainer):\n",
    "        trainer.__training_epoch = True\n",
    "\n",
    "    def on_fit_epoch_end(trainer):\n",
    "        if trainer.__training_epoch:\n",
    "            all_metrics = {\n",
    "                **trainer.label_loss_items(trainer.tloss, prefix=\"train\"),\n",
    "                **trainer.metrics,\n",
    "            }\n",
    "            for metric, value in all_metrics.items():\n",
    "                live.log_metric(metric, value)\n",
    "\n",
    "            live.next_step()\n",
    "            trainer.__training_epoch = False\n",
    "\n",
    "    def on_train_end(trainer):\n",
    "        all_metrics = {\n",
    "            **trainer.label_loss_items(trainer.tloss, prefix=\"train\"),\n",
    "            **trainer.metrics,\n",
    "        }\n",
    "        for metric, value in all_metrics.items():\n",
    "            live.log_metric(metric, value, plot=False)\n",
    "\n",
    "        _log_confusion_matrix(trainer.validator, live)\n",
    "\n",
    "        for image_path in trainer.validator.plots.keys():\n",
    "            if \"val_batch\" in image_path.name:\n",
    "                live.log_image(image_path.name, image_path)\n",
    "\n",
    "        if trainer.best.exists():\n",
    "            live.log_artifact(\n",
    "                trainer.best, name=\"pool-segmentation\", type=\"model\", copy=True,\n",
    "                desc=\"This is a Computer Vision (CV) model that's segmenting out swimming pools from satellite images.\",\n",
    "                labels=[\"cv\", \"segmentation\", \"satellite-images\", \"yolo\"],\n",
    "            )\n",
    "\n",
    "    yolo.callbacks[\"on_train_epoch_start\"].append(on_train_epoch_start)\n",
    "    yolo.callbacks[\"on_fit_epoch_end\"].append(on_fit_epoch_end)\n",
    "    yolo.callbacks[\"on_train_end\"].append(on_train_end)\n",
    "\n",
    "    return yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgsz = 384\n",
    "epochs = 20\n",
    "model = \"yolov8n-seg.pt\"\n",
    "results_dir = ROOT / \"results\" / \"train\"\n",
    "\n",
    "yolo = YOLO(model)\n",
    "\n",
    "with Live(str(results_dir), save_dvc_exp=True, report=None, cache_images=True) as live:\n",
    "    live.log_params({\n",
    "        \"epochs\": epochs,\n",
    "        \"imgsz\": imgsz,\n",
    "        \"model\": model\n",
    "    })\n",
    "    yolo = add_callbacks(live, yolo)\n",
    "    yolo.train(data=(DATA / \"yolo_dataset.yaml\").resolve(), epochs=epochs, imgsz=imgsz)\n",
    "\n",
    "try:\n",
    "    os.remove(DATA / \"yolo_dataset\" / \"train.cache\")\n",
    "    os.remove(DATA / \"yolo_dataset\" / \"val.cache\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "shutil.rmtree(\"../runs\", ignore_errors=True)\n",
    "shutil.rmtree(\"../weights\", ignore_errors=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
